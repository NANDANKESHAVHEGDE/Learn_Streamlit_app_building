{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea8d7ea3",
   "metadata": {
    "code_folding": [
     13
    ]
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data Generation\n",
    "np.random.seed(42)\n",
    "num_samples = 10000  # number of samples can be increased as needed\n",
    "data = {\n",
    "    'Undergraduate_GPA': np.random.randint(3,4, num_samples),\n",
    "    'Highest_degree':np.random.choice(['Bachelors','Masters','Other_three_year_degree'], num_samples),\n",
    "    'Relevant_DataScience_Experience ': np.random.uniform(0,8, num_samples),\n",
    "    'Degree_seeking_Type': np.random.choice(['Masters','PHD'], num_samples),\n",
    "    'Apply_Year': np.random.randint(2020,2023, num_samples),\n",
    "    'Country': np.random.choice(['United States','Canada','Asia','Europe','India'], num_samples),\n",
    "    'Uploaded_Statement_of_Purpose_Status': np.random.choice(['Y', 'N'], num_samples),\n",
    "    'Uploaded_Resume_Status': np.random.choice(['Y', 'N'], num_samples),  # Assuming the candidate is confident of his/her abilities\n",
    "    'GRE_Score': np.random.randint(300,325, num_samples),\n",
    "    'IELTS_Overall': np.random.randint(5,10, num_samples),\n",
    "    'TOEFL_Overall': np.random.choice([90,100], num_samples),\n",
    "    'Gender': np.random.choice(['M','F'], num_samples),\n",
    "    'DataScience_Skill_Confidence': np.random.randint(0,10, num_samples),\n",
    "    'Admit_label': np.random.choice([0, 1], num_samples)  # Binary target variable (approved or declined)\n",
    "}\n",
    "\n",
    "def preprocess_data_train(df):\n",
    "    # Feature Scaling/Normalization (you can customize this based on your data)\n",
    "    numerical_columns = df.drop(columns = ['Admit_label']).select_dtypes(include=[np.number]).columns\n",
    "    df[numerical_columns] = (df[numerical_columns] - df[numerical_columns].mean()) / df[numerical_columns].std()\n",
    "    return df\n",
    "df = pd.DataFrame(data)\n",
    "df = preprocess_data_train(df)\n",
    "# Separate features and labels\n",
    "X = df.drop('Admit_label', axis=1)\n",
    "y = df['Admit_label']\n",
    "# Create dummy variables for categorical features\n",
    "X = pd.get_dummies(X, columns=['Degree_seeking_Type', 'Highest_degree','Country', 'Uploaded_Statement_of_Purpose_Status', 'Uploaded_Resume_Status', 'Gender'], drop_first=True)\n",
    "df = pd.concat([df, X],axis=1)\n",
    "df = df.drop(columns={'Degree_seeking_Type','Highest_degree','Country', 'Uploaded_Statement_of_Purpose_Status', 'Uploaded_Resume_Status', 'Gender'},axis=1)\n",
    "df = df.T.drop_duplicates().T\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Train XGBoostClassifier\n",
    "clf_xgb = XGBClassifier(n_estimators=100, random_state=42)\n",
    "clf_xgb.fit(X_train,y_train)\n",
    "# Evaluate the model on the validation set\n",
    "y_val_pred = clf_xgb.predict(X_val)\n",
    "# Display evaluation metrics\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "# Save the trained XGBoostClassifier model\n",
    "pickle.dump(clf_xgb, open('xgb_Admit_predictor_model.sav', 'wb'))\n",
    "# Save dummy data for reference\n",
    "df.to_csv('sample_Admit_predictor_model_training_data.csv', index=False)\n",
    "\n",
    "# Lets Deploy the Base iteration model in the Streamlit app \n",
    "def user_input_features():\n",
    "    apply_year = st.number_input(\"Apply_Year\",min_value=2024, max_value=2025)\n",
    "    undergraduate_gpa = st.number_input(\"Undergraduate_GPA\",min_value=3.0, max_value=4.0,step = 0.1)\n",
    "    gender = st.selectbox(\"Gender\", ('M', 'F'))\n",
    "    resume_status = st.selectbox(\"Uploaded_Resume_Status\", ('Y', 'N'))\n",
    "    sop_status = st.selectbox(\"Uploaded_Statement_of_Purpose_Status\", ('Y', 'N'))\n",
    "    relevant_datascience_experience = st.number_input(\"Relevant_DataScience_Experience\", min_value=0, max_value=8, step=1)\n",
    "    gre_score = st.number_input(\"GRE_Score\", min_value=300, max_value=325, step=1)\n",
    "    ielts_overall = st.number_input(\"IELTS_Overall\", min_value=5.0, max_value=10.0, step = 0.5)\n",
    "    toefl_overall = st.number_input(\"TOEFL_Overall\", min_value=90, max_value=110, step=1)\n",
    "    datascience_skill_confidence = st.number_input(\"DataScience_Skill_Confidence\", min_value=0, max_value=10, step=1)\n",
    "    degree_seeking_type = st.selectbox(\"Degree_seeking_Type\",('Masters','PHD'))\n",
    "    highest_degree = st.selectbox(\"Highest_degree\",('Bachelors','Masters','Other_three_year_degree'))\n",
    "    country = st.selectbox(\"Country\",('United States','Canada','Asia','Europe','India'))\n",
    "    data = {'Apply_Year': apply_year,\n",
    "            'Undergraduate_GPA': undergraduate_gpa,\n",
    "            'Gender': gender,\n",
    "            'Uploaded_Resume_Status': resume_status,\n",
    "            'Uploaded_Statement_of_Purpose_Status': sop_status,\n",
    "            'Relevant_DataScience_Experience': relevant_datascience_experience,\n",
    "            'GRE_Score': gre_score,\n",
    "            'IELTS_Overall': ielts_overall,\n",
    "            'TOEFL_Overall': toefl_overall,\n",
    "            'DataScience_Skill_Confidence': datascience_skill_confidence,\n",
    "            'Degree_seeking_Type': degree_seeking_type,\n",
    "            'Highest_degree': highest_degree,\n",
    "            'Country': country,\n",
    "           }\n",
    "    features = pd.DataFrame(data, index=[0])\n",
    "    return features\n",
    "def preprocess_data_predict(df):\n",
    "    numerical_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    # Feature Scaling/Normalization (you can customize this based on your data)\n",
    "    df[numerical_columns] = (df[numerical_columns] - df[numerical_columns].mean()) / df[numerical_columns].std()\n",
    "    return df\n",
    "def run_app(clf_xgb):\n",
    "    st.write(\"\"\"\n",
    "    # Admit Predictor for MS in Applied Data Science\n",
    "    This app generously predicts the probability of admit based on custom input parameters\n",
    "    \"\"\")\n",
    "    # Get Input\n",
    "    st.header('User Input Parameters')\n",
    "    df_input = user_input_features()\n",
    "    df_input = preprocess_data_predict(df_input)\n",
    "    st.subheader('User Input parameters')\n",
    "    st.write(df_input.to_dict())\n",
    "    # Create dummy variables for categorical features\n",
    "    cat_features = ['Degree_seeking_Type','Highest_degree','Country', 'Uploaded_Statement_of_Purpose_Status', 'Uploaded_Resume_Status', 'Gender']\n",
    "    df_input_encoded = pd.get_dummies(df_input, columns=cat_features, drop_first=True)\n",
    "    # Add missing columns with default values\n",
    "    missing_columns = set(clf_xgb.get_booster().feature_names) - set(df_input_encoded.columns)\n",
    "    for col in missing_columns:\n",
    "        df_input_encoded[col] = 0\n",
    "    # Reorder columns to match the model's feature names\n",
    "    df_input_encoded = df_input_encoded[clf_xgb.get_booster().feature_names]\n",
    "    # Model Loading\n",
    "    clf_xgb = pickle.load(open('xgb_Admit_predictor_model.sav', 'rb'))\n",
    "    # Model Inferencing\n",
    "    prediction = clf_xgb.predict(df_input_encoded)\n",
    "    prediction_proba = clf_xgb.predict_proba(df_input_encoded)\n",
    "    st.subheader('Prediction')\n",
    "    if prediction == 0:\n",
    "        st.write('Declined')\n",
    "    else:\n",
    "        st.write('Admitted')\n",
    "    st.subheader('Prediction Probability')\n",
    "    st.write(prediction_proba)\n",
    "if __name__ == '__main__':\n",
    "    run_app(clf_xgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "390.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
